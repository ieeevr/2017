

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Doctoral Consortium</title>
  
  <meta name="author" content="">

  <!-- Enable responsive viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Bootstrap styles -->
  <link href="/2017/assets/themes/ieee_vr_2017/css/style.css" rel="stylesheet"/>
  <!-- Sticky Footer -->
  <link href="/2017/assets/themes/ieee_vr_2017/css/bs-sticky-footer.css" rel="stylesheet">

  

  <!-- Custom styles -->
  <!--<link href="/2017/assets/themes/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">-->

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
  <![endif]-->

  <!-- Fav and touch icons -->
  <!-- Update these with your own images
  <link rel="shortcut icon" href="images/favicon.ico">
  <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
  <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
-->

<!-- atom & rss feed -->
  <link href="" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
  <link href="" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">


</head>

<body>


  <div id="wrap">
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#jb-navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="/2017/">IEEE Virtual Reality 2017</a>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="jb-navbar-collapse">
        
	

<ul class="nav navbar-nav">
    
				
				<li class="dropdown">
						<a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Program<span class="caret"></span></a>
						
	<!---->
	

<ul class="dropdown-menu">
    
				
        <li class=" ">
            <a href="/2017/program/overview.html">Overview</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/keynotes.html">Keynotes</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/papers.html">Papers</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/panels.html">Panels</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/posters.html">Posters</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/demos.html">Research Demos</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/videos.html">Videos</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/tutorials.html">Tutorials</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/workshops.html">Workshops</a>

        </li>
				
    
				
        <li class="active ">
            <a href="/2017/program/dc.html">Doctoral Consortium</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/exhibitors.html">Exhibitors</a>

        </li>
				
    
</ul>

				</li>
				
    
				
				<li class="dropdown">
						<a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Attend<span class="caret"></span></a>
						
	<!---->
	

<ul class="dropdown-menu">
    
				
        <li class=" ">
            <a href="/2017/attend/registration.html">Registration</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/attend/accommodations.html">Accomodations</a>

        </li>
				
    
</ul>

				</li>
				
    
				
				<li class="dropdown">
						<a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Contribute<span class="caret"></span></a>
						
	<!---->
	

<ul class="dropdown-menu">
    
				
        <li class=" ">
            <a href="/2017/contribute/papers.html">Call for Papers</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/panels.html">Call for Panels</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/posters.html">Call for Posters</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/tutorials.html">Call for Tutorials</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/researchDemos.html">Call for Research Demos</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/workshops.html">Call for Workshops</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/videos.html">Call for Videos</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/docConsortium.html">Call for Doctoral Consortium</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/studentVolunteers.html">Call for Student Volunteers</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/exhibitors.html">Exhibitors and Supporters</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/formatting.html">Formatting Guidelines</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/contribute/presentation.html">Presentation Guidelines</a>

        </li>
				
    
</ul>

				</li>
				
    
				
				<li class="dropdown">
						<a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Committees<span class="caret"></span></a>
						
	<!---->
	

<ul class="dropdown-menu">
    
				
        <li class=" ">
            <a href="/2017/committees/conference.html">Conference Committee</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/committees/steering.html">Steering Committee</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/committees/program.html">Program Committee</a>

        </li>
				
    
</ul>

				</li>
				
    
				
        <li class=" ">
            <a href="/2017/awards/">Awards</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/past-conferences/">Past Conferences</a>

        </li>
				
    
				
        <li class=" ">
            <a href="/2017/program/3dui.html">3DUI 2017</a>

        </li>
				
    
</ul>

      </div><!-- /.navbar-collapse -->
    </nav>
    <div class="container-fluid fill-height">
      <div class="row">
        <div class="row-lg-height row-md-height">
          <div id="logoandsponsors" class="col-lg-5 col-md-6 col-sm-12 col-lg-height col-md-height">
            <div style="width=100%; height: 450px; background-color: #000; margin-left: -15px;" class="hidden-xs hidden-sm">
              <img src="/2017/assets/themes/ieee_vr_2017/images/palmtree-large-transparent-white-text-maroon-v2.png"
              width="491" height="auto" alt="2017 IEEE VR Los Angeles logo"
              class="pull-right" style="margin-top: 50px; margin-bottom: 30px; margin-right: 45px;"/>
            </div>
            <div style="width=100%; background-color: #000; margin-left: -15px; margin-right: -15px;" class="visible-sm">
              <img src="/2017/assets/themes/ieee_vr_2017/images/palmtree-large-transparent-white-text-maroon-v2.png"
              width="491" height="auto" alt="2017 IEEE VR Los Angeles logo"
              class="center-block" style="padding-top: 50px; padding-bottom: 30px;"/>
            </div>
            <div style="width=100%; background-color: #000; margin-left: -15px; margin-right:-15px;" class="visible-xs">
              <img src="/2017/assets/themes/ieee_vr_2017/images/palmtree-large-transparent-white-text-maroon-v2.png"
              width="60%" height="auto" alt="2017 IEEE VR Los Angeles logo"
              class="center-block" style="vertical-align: middle; padding-top: 50px; padding-bottom: 30px"/>
            </div>

            <div class="row">
              <!-- Sponsor and social media (or other "float left column" content lives here for LG and MD windows)-->
              <div class="col-lg-12 col-md-12 pull-right visible-lg visible-md">
                <img src="/2017/assets/themes/ieee_vr_2017/images/ieee-cs-logo-white-transparent-stacked.png"
                width="150" height="54" style="margin-top: 25px; margin-bottom: 25px; margin-right: 40px" alt="IEEE Computer Society" class="pull-right"/>
                <img src="/2017/assets/themes/ieee_vr_2017/images/ieee-logo-white-transparent.png"
                width="150" height="44" style="margin-top: 25px; margin-bottom: 25px; margin-right: 40px" alt="IEEE" class="pull-right"/>
				<a href="https://twitter.com/ieeevr"><img style="height: 40px; margin-top: 25px; margin-bottom: 25px; margin-right: 40px; margin-left: 2px;" src="/2017/img/twitter.png" class="pull-right"/></a>
				<a href="https://facebook.com/ieeevr"><img style="height: 40px; margin-top: 25px; margin-bottom: 25px; margin-right: 2px;" src="/2017/img/facebook.png" class="pull-right"/></a>
              </div>
            </div>
			
			<div class="row">
              <!-- Sponsor and social media (or other "float left column" content lives here for LG and MD windows)-->
              <div class="col-lg-12 col-md-12 pull-right visible-lg visible-md" style="text-align: center; width: 400px; margin-top: 30px;  margin-bottom: 2px; margin-right: 100px; background-color: #000; color: #fff">
				<h4><b>Exhibitors and Supporters</b></h4>
              </div>
            </div>
			
			<div class="row">
              <!-- Sponsor and social media (or other "float left column" content lives here for LG and MD windows)-->
              <div class="col-lg-12 col-md-12 pull-right visible-lg visible-md" style="text-align: center; width: 300px; margin-right: 150px; margin-bottom: 50px; background-color: #fff; padding-left: 60px; padding-right: 60px; padding-bottom: 30px; padding-top: 10px;">
				<h4>Silver Level</h4>


<img src="/2017/img/exhibitors/ART.jpg" alt="logo" style="width: 85%"/>

<br><br>

<img src="/2017/img/exhibitors/phasespace_logo.jpg" alt="logo" style="width: 100%"/>

<br><br><br>

<h4>Bronze Level</h4>

<img src="/2017/img/exhibitors/ARL.jpg" alt="logo" style="width: 60%"/>

<br><br>

<img src="/2017/img/exhibitors/DigitalProjection.jpg" alt="logo" style="width: 100%"/>

<br><br>

<img src="/2017/img/exhibitors/Haption.jpg" alt="logo" style="width: 80%"/>

<br><br>

<img src="/2017/img/exhibitors/MiddleVR.jpg" alt="logo" style="width: 100%"/>

<br><br>

<img src="/2017/img/exhibitors/Polhemus.jpg" alt="logo" style="width: 100%"/>

<br><br>

<img src="/2017/img/exhibitors/Technicolor.jpg" alt="logo" style="width: 100%"/>

<br><br>

<img src="/2017/img/exhibitors/Vicon.jpg" alt="logo" style="width: 100%"/>

<br><br>

<img src="/2017/img/exhibitors/logo_vr_on.jpg" alt="logo" style="width: 100%"/>

<br><br>

<img src="/2017/img/exhibitors/vrvana.jpg" alt="logo" style="width: 100%"/>

<br><br>

<img src="/2017/img/exhibitors/worldviz.jpg" alt="logo" style="width: 100%"/>

<br><br><br>

<h4>Event Supporters</h4>

<img src="/2017/img/exhibitors/ICT.jpg" alt="logo" style="width: 100%"/>

<br><br>

<img src="/2017/img/exhibitors/postmedia.jpg" alt="logo" style="width: 100%"/>

<br><br><br>

<h4>Publisher</h4>

<img src="/2017/img/exhibitors/Frontiers.jpg" alt="logo" style="width: 100%"/>


<br><br><br>


<h4>Other Supporters</h4>

<img src="/2017/img/exhibitors/oben.jpg" alt="logo" style="width: 100%"/>

<br><br>

<img src="/2017/img/exhibitors/UTDallas.jpg" alt="logo" style="width: 100%"/>


              </div>
            </div>
			
			
          </div>
          <div class="col-lg-5 col-md-6 col-sm-12 col-lg-height col-md-height col-lg-top col-md-top" style="background-color: #fff; padding-top: 20px; padding-left: 40px; padding-right: 40px; padding-bottom: 40px; box-shadow: inset 0 0 10px 10px #000;">
            <h1 id="doctoral-consortium">Doctoral Consortium</h1>

<p><br /></p>

<div class="row">
    <div class="col-xs-12">
        <table class="table-responsive program-table">
            <tr>
                <td class="program-days"><h4>Saturday<br />March 18</h4></td>
            </tr>
			<tr>
                <td class="program-vr-session">
					<div class="program-time">8:30am - 5:00pm</div>
				</td>
            </tr>
        </table>
    </div>
</div>

<p><a name="Doctoral Consortium"><br /></a></p>

<p><a name="Steering Locomotion by Vestibular Pertubation in Room-Scale VR"> </a></p>

<h4 id="steering-locomotion-by-vestibular-pertubation-in-room-scale-vr">Steering Locomotion by Vestibular Pertubation in Room-Scale VR</h4>

<p><em>Misha Sra</em></p>

<p>Abstract: Advances in consumer virtual reality (VR) technology have made using natural locomotion for navigation in VR a possibility. While walking in VR can enhance immersion and reduce motion sickness, it introduces a few challenges. Walking is only possible within virtual environments (VEs) that fit inside the boundaries of the tracked physical space, which for most users is quite small and carries a high potential for collisions with physical objects around the tracked area. In my thesis, I explore visual and physiological steering techniques that complement the traditional redirected walking technique of scene rotation to alter a user's walking trajectory in the physical space. In this paper, I present the physiological technique.</p>

<p><a name="Cognitive Psychology and Human Factors Engineering of Virtual Reality"> </a></p>

<h4 id="cognitive-psychology-and-human-factors-engineering-of-virtual-reality">Cognitive Psychology and Human Factors Engineering of Virtual Reality</h4>

<p><em>Adrian K. T. Ng</em></p>

<p>Abstract: This position paper summarizes the author's research interest in Cognitive Psychology and Human-Computer Interaction in the imseCAVE, a CAVE-like system in the University of Hong Kong. Several areas of interest were explored while finding the thesis topic for the Ph.D. research. They include a perception research on distance estimation with proposed error correction mechanism, neurofeedback meditation with EEG in VR and the effect with audio and video, the study of training transfer in VR training, the comparison and research of cybersickness between HMD and the imseCAVE, and comparing VR gaming in TV, HMD, and the imseCAVE by performance, activity level and time perception. With a broad interest, the exact direction is still in the search and requires future exploration.</p>

<p><a name="Design and Assessment of Haptic Interfaces: An Essay on Proactive Haptic Articulation"> </a></p>

<h4 id="design-and-assessment-of-haptic-interfaces-an-essay-on-proactive-haptic-articulation">Design and Assessment of Haptic Interfaces: An Essay on Proactive Haptic Articulation</h4>

<p><em>Victor Adriel de Jesus Oliveira, Luciana Nedel, and Anderson Maciel</em></p>

<p>Abstract: We looked up to elements present in speech articulation to introduce the proactive haptic articulation as a novel approach for intercommunication. The ability to use a haptic interface as a tool for implicit communication can supplement communication and support near and remote collaborative tasks in virtual and physical environments. In addition, the proactive articulation can be applied during the design process, including the user in the construction of more dynamic and optimized vibrotactile vocabularies. In this proposal, we discuss the thesis of the haptic proactive communication and our method to assess and implement it. Our goal is to understand the phenomena related to the proactive articulation of haptic signals and its use for communication and for the design of optimized tactile vocabularies.</p>

<p><a name="Designing Next Generation Marketplace: The Effect of 3D VR Store Interface Design Shopping Behavior"> </a></p>

<h4 id="designing-next-generation-marketplace-the-effect-of-3d-vr-store-interface-design-shopping-behavior">Designing Next Generation Marketplace: The Effect of 3D VR Store Interface Design Shopping Behavior</h4>

<p><em>Hyo Jeong Kang, Jung-hye Shin, and Kevin Ponto</em></p>

<p>Abstract: The medium of virtual reality enables new opportunities for the experience products and shopping environment that may combine best features of both physical and digital market place. As little is known on how best to create virtual reality marketplace, the current research aims to explore required features for VR market user interface and its impact on shopping behavior. As a first step toward endeavor, we will empirically test three different user interfaces; 2D interface style, 3D skeuomorphic interface style and interface that combines features of both 2D and 3D inter-action techniques.</p>

<p><a name="Gaze Estimation Based on Head Movements in Virtual Reality Applications using Deep Learning"> </a></p>

<h4 id="gaze-estimation-based-on-head-movements-in-virtual-reality-applications-using-deep-learning">Gaze Estimation Based on Head Movements in Virtual Reality Applications using Deep Learning</h4>

<p><em>Agata Marta Soccini and Marco Grangetto</em></p>

<p>Abstract: Gaze detection in Virtual Reality systems is mostly performed using eye-tracking devices. The coordinates of the sight, as well as other data regarding the eyes, are used as input values for the applications. While this trend is becoming more and more popular in the interaction design of immersive systems, most visors do not come with an embedded eye-tracker, especially those that are low cost and maybe based on mobile phones.  We suggest implementing an innovative gaze estimation system into virtual environments as a source of information regarding users intentions.  We propose a solution based on a combination of the features of the images and the movement of the head as an input of a Deep Convolutional Neural Network capable of inferring the 2D gaze coordinates in the imaging plane.</p>

<p><a name="On Exploring the Mitigation of Distance Misperception in Virtual Reality"> </a></p>

<h4 id="on-exploring-the-mitigation-of-distance-misperception-in-virtual-reality">On Exploring the Mitigation of Distance Misperception in Virtual Reality</h4>

<p><em>Alex Peer</em></p>

<p>Abstract: Misperception of egocentric distances in virtual reality is a well established effect, with many known influencing factors but no clear cause or correction. Herein is proposed a course of research that explores this effect on three fronts: exploring perceptual calibrations, corrections based on known influences and observed misperception rather than a perfect understanding of the causes of misperception; exploring when adaptations due to feedback might exhibit undesirable effects; establishing contexts within practical tasks when distance misperceptions should be expected to have an effect.</p>

<p><a name="Optical See-Through vs. Spatial Augmented Reality Simulators for Medical Applications"> </a></p>

<h4 id="optical-see-through-vs-spatial-augmented-reality-simulators-for-medical-applications">Optical See-Through vs. Spatial Augmented Reality Simulators for Medical Applications</h4>

<p><em>Salam Daher</em></p>

<p>Abstract: Currently healthcare practitioners use standardized patients, physical mannequins, and virtual patients as surrogates for real patients to provide a safe learning environment for students. Each of these simulators has different limitation that could be mitigated with various degrees of fidelity to represent medical cues. As we are exploring different ways to simulate a human patient and their effects on learning, we would like to compare the dynamic visuals between spatial augmented reality and a optical see-through augmented reality where a patient is rendered using the HoloLens and how that affects depth perception, task completion, and social presence.</p>

<p><a name="Design of Collaborative 3D User Interfaces for Virtual and Augmented Reality"> </a></p>

<h4 id="design-of-collaborative-3d-user-interfaces-for-virtual-and-augmented-reality">Design of Collaborative 3D User Interfaces for Virtual and Augmented Reality</h4>

<p><em>Jeronimo Grandi and Anderson Macie</em></p>

<p>Abstract: We explore design approaches for cooperative work in virtual manipulation tasks. We seek to understand the fundamental aspects of the human cooperation and design interfaces and manipulation actions to enhance the group’s ability to solve complex manipulation tasks in various immersion scenarios.</p>

<p><a name="Improve Accessibility of Virtual and Augmented Reality for People with Balance Impairments"> </a></p>

<h4 id="improve-accessibility-of-virtual-and-augmented-reality-for-people-with-balance-impairments">Improve Accessibility of Virtual and Augmented Reality for People with Balance Impairments</h4>

<p><em>Sharif Mohammad Shahnewaz Ferdous and John Quarles</em></p>

<p>Abstract: Most people experience some imbalance in a fully immersive Virtual Environment (VE) (i.e., wearing a Head Mounted Display (HMD) that blocks the users view of the real world). However, this imbalance is significantly worse in People with Balance Impairments (PwBIs) and minimal research has been done to improve this. In addition to imbalance problem, lack of proper visual cues can lead to different accessibility problems for PwBIs (e.g., small reach from the fear of imbalance, decreased gait performance, etc.) We plan to explore the effects of different visual cues on peoples’ balance, reach, gait, etc. Based on our primary study, we propose to incorporate additional visual cues in VEs that proved to significantly improve balance of PwBIs while they are standing and playing in a VE. We plan to further investigate if additional visual cues have similar effects in augmented reality. We are also developing studies to research reach and gait in VR as our future work.</p>

<p><a name="Wide Field of View Varifocal Near-Eye Displays"> </a></p>

<h4 id="wide-field-of-view-varifocal-near-eye-displays">Wide Field of View Varifocal Near-Eye Displays</h4>

<p><em>David Dunn</em></p>

<p>Accommodative depth cues, a wide field of view, and ever-higher resolutions all present major hardware design challenges for near-eye displays. Optimizing a design to overcome one of these challenges typically leads to a trade-off in the others. In work being published at IEEEVR 2017, my collaborators and I tackle this problem by introducing an all-in-one solution – a new wide field of view gaze- tracked near-eye display for augmented reality applications. The key component of our solution is the use of a single see-through varifocal deformable membrane mirror for each eye reflecting a display. They are controlled by airtight cavities and change the effective focal power to present a single image at a target depth plane which is determined by the gaze tracker. I propose that this work and my future work in evaluating the perceptual qualities of this display and in decreasing the size to a head-mountable form factor are the topic of my dissertation.</p>

<p><a name="View-Aware Tile-Based Adaptations in 360 Virtual Reality Video Streaming"> </a></p>

<h4 id="view-aware-tile-based-adaptations-in-360-virtual-reality-video-streaming">View-Aware Tile-Based Adaptations in 360 Virtual Reality Video Streaming</h4>

<p><em>Mohammad Hosseini</em></p>

<p>Abstract: We have proposed an adaptive view-aware bandwidth-efficient 360 VR video streaming framework based on the tiling features of MPEG-DASH SRD. We extend MPEG-DASH SRD to the 3D space of 360 VR videos, and showcase a dynamic view-aware adaptation technique to tackle the high bandwidth demands of streaming 360 VR videos to wireless VR headsets. As a part of our contributions, we spatially partition the underlying 3D mesh into multiple 3D sub-meshes, and construct an efficient 3D geometry mesh called "hexaface sphere" to optimally represent tiled 360 VR videos in the 3D space. We then spatially divide the 360 videos into multiple tiles while encoding and packaging, use MPEG-DASH SRD to describe the spatial relationship of tiles in the 3D space, and prioritize the tiles in the Field of View (FoV) for view-aware adaptation. The initial evaluations that we conducted show that we can save up to 72% of the required bandwidth on 360 VR video streaming with minor negative quality impacts compared to the baseline scenario when no adaptations is applied.</p>

<p><a name="Informing New Methods of Driver HUD Assessment"> </a></p>

<h4 id="informing-new-methods-of-driver-hud-assessment">Informing New Methods of Driver HUD Assessment</h4>

<p><em>Martha Smith</em></p>

<p>Abstract: Optical See Through Head Up Displays (HUDs) have recently gained popularity in a variety of applications, including driving. HUDs display transparent images directly onto the windshield of a vehicle, providing a relatively seamless transition between the display image and the road ahead. Recent research has explored how HUDs impact drivers and the research to date has been promising. HUDs have frequently been associated with improved driving performance. However, HUDs also receive mixed or negative reviews with respect to driving performance. These findings indicate the potential usefulness of AR HUDs, but the contradiction in performance implies that AR HUDs either may not be useful in all scenarios or they need to be better designed. Driving is inherently a dangerous task, with even the smallest of vehicles at slow speeds able to cause significant damage to pedestrians. Therefore, it is vital to sufficiently test HUDs before widely incorporating them into vehicles. A number of automotive manufacturers (e.g. BMW, Cadillac, Buick, Ford, Lexus) already use simple HUDs, indicating the need for a timely method of assessment.</p>

          </div>
          <div class="col-lg-2 col-lg-height col-md-height hidden-md hidden-sm hidden-xs" style="background-color: #000; height: 450px;"> &nbsp;</div>
        </div>
      </div>
    </div>
    <!-- Sponsor and social media (or other "float left column" content lives here for SM and XS windows)-->
    <!--
    <div class="row visible-sm visible-xs">
    <div class="col-sm-12">
    <h2>Sponsors</h2>
    <p>Sponsor images and links live here</p>
  </div>
</div>-->
</div>

<div id="footer">
  <div class="container">
    <p>
      &copy; 2017 webchairs2017 [at] ieeevr.org
    </p>
  </div>
</div>






<!-- Latest compiled and minified JavaScript, requires jQuery 1.x (2.x not supported in IE8) -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<!--<script src="/2017/assets/themes/bootstrap/js/bootstrap.min.js"></script>-->
<script src="/2017/assets/javascripts/bootstrap.min.js"></script>
</body>
</html>

